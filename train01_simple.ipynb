{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54130b95-d6ad-472a-80ac-6809c479e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import coral_ordinal as coral\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# !conda install emoji==0.6.0\n",
    "# !conda install --upgrade transformers\n",
    "# !conda install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0005e3f4-0c7a-4322-b6db-5b8b42f576a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80234b7a-98ac-497e-a1b5-fb4e2b347707",
   "metadata": {},
   "source": [
    "The Hugging Face transformers library...\n",
    "\n",
    "Let's start by importing Distilbert, the base pre-trained transformer model that Hugging Face recommends for sentiment analysis.\n",
    "This binary classification model evaluates a line of text and returns the predicted sentiment label and a score assessing the\n",
    "model's confidence. We can try this model out without any fine-tuning using the pipeline function by passing a few famous movie\n",
    "lines as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6f4215-db87-4a10-8bd7-510ed7a34fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997339844703674}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "cf_default = pipeline(\"sentiment-analysis\")\n",
    "cf_default(\"Today, I consider myself the luckiest man on the face of the earth.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefe4984-0e15-48e7-9ce3-10baafa9cbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9993259906768799}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_default(\"I'm as mad as hell, and I'm not going to take this anymore!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135f0b8-118d-4eef-b6ab-adccd97b173c",
   "metadata": {},
   "source": [
    "The tweet_eval dataset available on Hugging Face consists of several labeled datasets of English language\n",
    "tweets for various classification tasks. The 'sentiment' sub-dataset contains tweets with one of three labels\n",
    "(indicating positive, negative, and neutral sentiment) and is divided into training, validation, and test splits.\n",
    "\n",
    "The Hugging Face datasets library's load_dataset() function provides a straightforward way to import\n",
    "the tweet_eval sentiment labeled dataset. Each of the splits will be typed as an instance of the simply named Dataset\n",
    "class, while the full sentiment data will be a DatasetDict including all of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477ccfd1-4b1f-4e60-8fea-9bf2fe37df02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (C:\\Users\\Kaya\\.cache\\huggingface\\datasets\\tweet_eval\\sentiment\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0e4ef3ab694d019c123948d7f0328a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tweet_eval\", \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64781f7-f9e5-4cdd-88f8-48ee91bd67a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 45615\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12284\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf978029-4bb0-41df-ac50-7c8cadaf37b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=3, names=['negative', 'neutral', 'positive'], id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41fb74a0-1bfb-4f0e-a785-50ad8535f7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Thanks manager for putting me on the schedule for Sunday\"',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa8f03-2cdc-444d-aaab-e7f8aa393f1b",
   "metadata": {},
   "source": [
    "Because the tweet_eval sentiment data has three label classes, the default binary classifier isn't a readily\n",
    "meaningful comparison point for assessing baseline performance without retraining. Instead we'll compile a three-way\n",
    "classifier starting with BERTweet, a refinement of BERT pre-trained on a corpus of twitter data. We can then re-train\n",
    "and evaluate BERTweet using the tweet_eval sentiment data that we've previously loaded. \n",
    "\n",
    "We'll start by using AutoTokenizer to load a tokenizer specifically suggested for use with BERTweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e146ef65-74c8-45f2-92e1-0f81bbdec920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645649fb-924e-4e7d-b137-47154b1cc3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 47, 1600, 3345, 9646, 13545, 141, 6, 2307, 10638, 4, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"The quick brown fox jumps over the lazy dog.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c80fb01-51d8-41b6-a496-9c4a213c8869",
   "metadata": {},
   "source": [
    "Next we'll tokenize the dataset. Each tokenized split will be a Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b47aa3-ff1f-427b-a1cd-b43e547f82dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_fn at 0x000001662DA15670> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f162e27eb164a47806a54f03e9a82af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0183a3896db4384b4d53fc898061470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a69f549c55e4e7499a9d71d47054ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c0bbd2-0a81-4b22-8ff4-d68ea44e054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 45615\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed1e2e7-c06f-4015-8194-9a7018a762fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91083814-c645-4220-91ef-6494b4a30a84",
   "metadata": {},
   "source": [
    "Now we convert the tokenized data to a TensorFlow compatible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d28657d6-7d61-4610-9c94-d22fcbbbabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import tf_default_data_collator\n",
    "\n",
    "data_collator = tf_default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "865e4668-ba24-45ff-9a8a-523c7967a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datasets\n",
    "\n",
    "tf_train_dataset = tokenized_dataset['train'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "tf_validation_dataset = tokenized_dataset['validation'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b8c8a-3448-41ae-98f4-f7fee10de746",
   "metadata": {},
   "source": [
    "Here we set parameters and create the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09990969-d213-4ae7-8360-f54292d1f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 3\n",
    "batches_per_epoch = len(tokenized_dataset[\"train\"]) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "optimizer, schedule = create_optimizer(init_lr=5e-6, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142fb29e-6eaf-475d-8b9e-88d6edd4b3cf",
   "metadata": {},
   "source": [
    "Now we'll use the transformers library's auto model functionality to create a TensorFlow model object appropriate\n",
    "for three-way classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "004fb9f7-dc46-4a10-84bf-d9a31888b5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "bertweet = TFAutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473c108-760f-4cd7-9475-a5c2862d2ca9",
   "metadata": {},
   "source": [
    "Finally it's time to compile and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9d85673-6a0f-4c94-b746-6710be4860bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\Kaya\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "5701/5701 [==============================] - 1462s 254ms/step - loss: 0.6399 - sparse_categorical_accuracy: 0.7120 - mean_absolute_error_labels: 0.6984 - val_loss: 0.5882 - val_sparse_categorical_accuracy: 0.7395 - val_mean_absolute_error_labels: 0.6970\n",
      "Epoch 2/3\n",
      "5701/5701 [==============================] - 1448s 254ms/step - loss: 0.5222 - sparse_categorical_accuracy: 0.7732 - mean_absolute_error_labels: 0.6963 - val_loss: 0.5772 - val_sparse_categorical_accuracy: 0.7460 - val_mean_absolute_error_labels: 0.6950\n",
      "Epoch 3/3\n",
      "5701/5701 [==============================] - 1447s 254ms/step - loss: 0.4634 - sparse_categorical_accuracy: 0.8008 - mean_absolute_error_labels: 0.6888 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.7450 - val_mean_absolute_error_labels: 0.6990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x166a812e9a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [tf.metrics.SparseCategoricalAccuracy(), coral.MeanAbsoluteErrorLabels()],\n",
    ")\n",
    "\n",
    "bertweet.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a186cce-a5fb-4f80-bbeb-8f8988ec8674",
   "metadata": {},
   "source": [
    "Judging from the validation loss figures, three epochs is a reasonable choice before the model starts to overfit.\n",
    "Now let's convert the tokenized test split to be compatible with TensorFlow and then evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a067619-dc30-4f4f-914d-41fcb028a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_dataset = tokenized_dataset['test'].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeeb3c4e-a2f6-40ad-90a7-92d93060a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536/1536 [==============================] - 123s 80ms/step - loss: 0.6389 - sparse_categorical_accuracy: 0.7190 - mean_absolute_error_labels: 0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6388965249061584, 0.718984067440033, 0.92236328125]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a95d43b-095c-4dcd-9d20-51e9b24f2972",
   "metadata": {},
   "source": [
    "The bertweet model achieves 0.7190 accuracy on the test split, not too bad of a stepdown from the performance on the \n",
    "training and validation splits, and comparable with other BERT-based sentiment classification models. We can try training\n",
    "for another epoch and see what effect that might have on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b7c9d68-1bec-4de8-b946-ae0d83392c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5701/5701 [==============================] - 1448s 254ms/step - loss: 0.4410 - sparse_categorical_accuracy: 0.8149 - mean_absolute_error_labels: 0.6764 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.7450 - val_mean_absolute_error_labels: 0.6990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x166eb7ceb20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03a46c16-a30d-4c34-8a45-62a806718ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536/1536 [==============================] - 123s 80ms/step - loss: 0.6389 - sparse_categorical_accuracy: 0.7190 - mean_absolute_error_labels: 0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6388965249061584, 0.718984067440033, 0.92236328125]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c760d-35a0-4d07-bbaf-7a11ec5432a3",
   "metadata": {},
   "source": [
    "There was no improvement in performance after the additional training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8230937-7fee-4e02-a71f-8fe71254afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet.save_pretrained(\"./models/bertweet_simple/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c040d55-5e84-4735-8a8b-c22ef8f284c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing RobertaModel.\n",
      "\n",
      "All the weights of RobertaModel were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "bertweet_load_test = AutoModel.from_pretrained(\"./models/bertweet_simple/\", from_tf=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
